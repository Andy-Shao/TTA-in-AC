{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Classification with CNN under Cross-Validation Experiment\n",
    "Try to analysis the data with,\n",
    "+ accuracy\n",
    "+ precision\n",
    "+ recall\n",
    "  \n",
    "both of training step and validation stage.\n",
    "Meanwhile, try to use the plot-box to demonstrates the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Cross-Validation under Multi-Classification\n",
    "`This explaination comes from the Chat-GPT4o.`\n",
    "Calculating precision and recall for a multi-class classification algorithm involves considering each class separately and then aggregating the results. Here's how you can do it step by step:\n",
    "\n",
    "### 1. Definitions\n",
    "\n",
    "- **Precision** for a class $C_i$: The ratio of true positive predictions for class $C_i$ to the total number of instances predicted as $C_i$ (i.e., true positives + false positives).\n",
    "  \n",
    "  $$\n",
    "  \\text{Precision}(C_i) = \\frac{\\text{True Positives}(C_i)}{\\text{True Positives}(C_i) + \\text{False Positives}(C_i)}\n",
    "  $$\n",
    "\n",
    "- **Recall** for a class $C_i $: The ratio of true positive predictions for class $ C_i $ to the total number of instances that actually belong to $ C_i $ (i.e., true positives + false negatives).\n",
    "\n",
    "  $$\n",
    "  \\text{Recall}(C_i) = \\frac{\\text{True Positives}(C_i)}{\\text{True Positives}(C_i) + \\text{False Negatives}(C_i)}\n",
    "  $$\n",
    "\n",
    "### 2. Confusion Matrix\n",
    "\n",
    "For a multi-class classification problem, you typically generate a confusion matrix, where each row represents the actual class, and each column represents the predicted class. The element at position $ (i, j) $ in the confusion matrix represents the number of instances of class $ i $ that were predicted as class $ j $.\n",
    "\n",
    "### 3. Calculation for Each Class\n",
    "\n",
    "- **True Positives (TP)**: The diagonal element for the class $ C_i $ in the confusion matrix, i.e., $ \\text{TP}(C_i) = \\text{Confusion Matrix}[i][i] $.\n",
    "- **False Positives (FP)**: The sum of the corresponding column $ i $ minus the true positives, i.e., $ \\text{FP}(C_i) = \\sum_j \\text{Confusion Matrix}[j][i] - \\text{Confusion Matrix}[i][i] $.\n",
    "- **False Negatives (FN)**: The sum of the corresponding row $ i $ minus the true positives, i.e., $ \\text{FN}(C_i) = \\sum_j \\text{Confusion Matrix}[i][j] - \\text{Confusion Matrix}[i][i] $.\n",
    "\n",
    "### 4. Precision and Recall for Each Class\n",
    "\n",
    "Using the definitions and the components from the confusion matrix, you can calculate precision and recall for each class $ C_i $:\n",
    "\n",
    "$$\n",
    "\\text{Precision}(C_i) = \\frac{\\text{TP}(C_i)}{\\text{TP}(C_i) + \\text{FP}(C_i)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Recall}(C_i) = \\frac{\\text{TP}(C_i)}{\\text{TP}(C_i) + \\text{FN}(C_i)}\n",
    "$$\n",
    "\n",
    "### 5. Aggregating Results\n",
    "\n",
    "To get overall metrics, you can use macro-averaging or micro-averaging:\n",
    "\n",
    "- **Macro-Averaging**: Calculate the metrics for each class independently and then take the average.\n",
    "\n",
    "  $$\n",
    "  \\text{Macro Precision} = \\frac{1}{N} \\sum_{i=1}^{N} \\text{Precision}(C_i)\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\text{Macro Recall} = \\frac{1}{N} \\sum_{i=1}^{N} \\text{Recall}(C_i)\n",
    "  $$\n",
    "\n",
    "- **Micro-Averaging**: Aggregate the contributions of all classes to calculate the metrics. Essentially, you sum up the true positives, false positives, and false negatives across all classes and then calculate precision and recall.\n",
    "\n",
    "  $$\n",
    "  \\text{Micro Precision} = \\frac{\\sum_{i=1}^{N} \\text{TP}(C_i)}{\\sum_{i=1}^{N} (\\text{TP}(C_i) + \\text{FP}(C_i))}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\text{Micro Recall} = \\frac{\\sum_{i=1}^{N} \\text{TP}(C_i)}{\\sum_{i=1}^{N} (\\text{TP}(C_i) + \\text{FN}(C_i))}\n",
    "  $$\n",
    "\n",
    "### Example\n",
    "\n",
    "Let's consider a simple example with three classes A, B, and C, and the following confusion matrix:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|ccc}\n",
    "    & \\text{Pred A} & \\text{Pred B} & \\text{Pred C} \\\\\n",
    "    \\hline\n",
    "    \\text{Actual A} & 40 & 5 & 5 \\\\\n",
    "    \\text{Actual B} & 3 & 50 & 2 \\\\\n",
    "    \\text{Actual C} & 2 & 4 & 45 \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "For class A:\n",
    "\n",
    "- $\\text{TP}(A) = 40$\n",
    "- $\\text{FP}(A) = 3 + 2 = 5$\n",
    "- $\\text{FN}(A) = 5 + 5 = 10$\n",
    "\n",
    "$$\n",
    "\\text{Precision}(A) = \\frac{40}{40 + 5} = \\frac{40}{45} \\approx 0.89\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Recall}(A) = \\frac{40}{40 + 10} = \\frac{40}{50} = 0.8\n",
    "$$\n",
    "\n",
    "You can calculate precision and recall similarly for classes B and C and then aggregate the results using macro-averaging or micro-averaging as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
